{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOrHwBCeNQsF",
        "outputId": "ef408227-78cf-4993-c75f-90d20b96fb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jKO0VzinOMd3"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtkLN5NhOHmN",
        "outputId": "bb692f87-8ada-45eb-b628-27f5dda4c05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-1.5-flash-002\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gWLEIm2DOQEh"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "298pa3l5Of3D",
        "outputId": "951e5c6a-af05-4a14-d021-afbd22f2dedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask me anything: hi\n",
            "Hello there! How can I assist you today?\n",
            "Ask me anything: who are you?\n",
            "I am Gemini, a multimodal AI language model developed by Google. I am designed\n",
            " to provide information, answer questions, and generate text based on the knowledge I have been trained on. I am not a specific person, but rather a computer program\n",
            " designed to assist users with a wide range of language-based tasks.\n",
            "Ask me anything: Exit\n"
          ]
        }
      ],
      "source": [
        "#test code for chat\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "while True:\n",
        "    prompt = input(\"Ask me anything: \")\n",
        "    if (prompt.lower() == \"exit\"):\n",
        "        break\n",
        "    response = chat.send_message(prompt, stream=True)\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "          print(chunk.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "onPluWQgTOyj"
      },
      "outputs": [],
      "source": [
        "def generate_questions_from_text(user_input):\n",
        "    prompt = f\"\"\"\n",
        "    Generate a set of questions based on the following description,\n",
        "    treat it like a comprehension text and strictly stick to it:\n",
        "    Only give questions in second person (you)\n",
        "    Donot Include any other text or index.\n",
        "    '{user_input} '\n",
        "    \"\"\"\n",
        "    response = chat.send_message(prompt, stream=True)\n",
        "\n",
        "    questions = \"\"\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "            questions += chunk.text\n",
        "\n",
        "    return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dOIiwWEXYkO-"
      },
      "outputs": [],
      "source": [
        "def preprocess(questions):\n",
        "    questions = questions.split('\\n')\n",
        "    questions_preprocessed = []\n",
        "    for question in questions:\n",
        "        question = question.lstrip(\" .123456789\")\n",
        "        if not \"question\" in question.lower() and len(question) > 10:\n",
        "            questions_preprocessed.append(question)\n",
        "    return questions_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TY-gmnoGXfuO"
      },
      "outputs": [],
      "source": [
        "def validate_responses(user_input, user_responses):\n",
        "    prompt = f\"Validate the following answers based on the user's description. Tell if each answer is correct/incorrect/partially correct Description: '{user_input}', Responses: {user_responses}\"\n",
        "    response = chat.send_message(prompt, stream=True)\n",
        "\n",
        "    validation_result = \"\"\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "            validation_result += chunk.text\n",
        "\n",
        "    return validation_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VfoDns_WZ610"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dz8mpxq0YCpx"
      },
      "outputs": [],
      "source": [
        "def authentication_conversation():\n",
        "    print(\"Welcome to the conversational authentication system.\")\n",
        "\n",
        "    user_input = input(\"Please describe yourself: \")\n",
        "\n",
        "    questions = generate_questions_from_text(user_input)\n",
        "    questions = preprocess(questions)\n",
        "\n",
        "\n",
        "    if len(questions) < 6:\n",
        "        print(\"Could not generate questions from the input. Please try again.\")\n",
        "        return\n",
        "\n",
        "    selected_questions = random.sample(questions, 4)\n",
        "\n",
        "    user_responses = {}\n",
        "    print(\"\\nPlease answer the following questions:\")\n",
        "    for question in selected_questions:\n",
        "        print(question)\n",
        "        user_responses[question] = input(\"Your answer: \")\n",
        "\n",
        "    validation_result = validate_responses(user_input, user_responses)\n",
        "    print(validation_result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "authentication_conversation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2OH0xXSvhmD",
        "outputId": "adc8cad4-afb7-4d9f-e395-60253a519247"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the conversational authentication system.\n",
            "Please describe yourself: I am John Doe, a virtual entity introduced for testing purposes. As a 25-year-old Software Engineer at ABC org, I combine technical expertise with a love for music and dance to approach challenges creatively. Whether collaborating with my close friends Percy and Jackson or solving complex problems at work, I'm always looking for new ways to innovate and improve\n",
            "\n",
            "Please answer the following questions:\n",
            "What is your profession?\n",
            "Your answer: SWE\n",
            "What is your primary goal in your work?\n",
            "Your answer: Innovate & improve\n",
            "How do you approach challenges?\n",
            "Your answer: Creatively\n",
            "What is your purpose as a virtual entity?\n",
            "Your answer: Testing\n",
            "* **What is your profession?**\n",
            "    * Correct\n",
            "\n",
            "* **What is your primary goal in your work?**\n",
            "    * Correct\n",
            "\n",
            "* **How do you approach challenges?**\n",
            "    * Correct\n",
            "\n",
            "* **What is your purpose as a virtual entity?**\n",
            "    * Correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "authentication_conversation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmYX8wyvxoPN",
        "outputId": "2d2c5fbb-cb73-43ea-90bd-4df0a357c3a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the conversational authentication system.\n",
            "Please describe yourself: I am John Doe, a virtual entity introduced for testing purposes. As a 25-year-old Software Engineer at ABC org, I combine technical expertise with a love for music and dance to approach challenges creatively. Whether collaborating with my close friends Percy and Jackson or solving complex problems at work, I'm always looking for new ways to innovate and improve\n",
            "\n",
            "Please answer the following questions:\n",
            "What is your purpose as a virtual entity?\n",
            "Your answer: Tester\n",
            "What are your hobbies and interests?\n",
            "Your answer: Music & Dancing\n",
            "Who are your close friends?\n",
            "Your answer: Pircy and jeckson\n",
            "How do you approach challenges?\n",
            "Your answer: With Creativity\n",
            "* **What is your purpose as a virtual entity?**\n",
            "    * Correct\n",
            "\n",
            "* **What are your hobbies and interests?**\n",
            "    * Correct\n",
            "\n",
            "* **Who are your close friends?**\n",
            "    * Partially correct (the description mentions \"Percy and Jackson\", while the response misspells their names)\n",
            "\n",
            "* **How do you approach challenges?**\n",
            "    * Correct\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}